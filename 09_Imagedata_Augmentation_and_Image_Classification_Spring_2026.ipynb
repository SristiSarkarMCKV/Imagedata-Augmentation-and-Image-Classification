{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SristiSarkarMCKV/Imagedata-Augmentation-and-Image-Classification/blob/main/09_Imagedata_Augmentation_and_Image_Classification_Spring_2026.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "intro-header"
      },
      "source": [
        "<div align=\"left\" style=\"background-color: #008080; padding: 20px 10px;\">\n",
        "<h3><b>IDEAS - Institute of Data Engineering, Analytics and Science Foundation</b></h3>\n",
        "<p>Spring Internship Program 2026</p>\n",
        "<hr style=\"width:100%;\">\n",
        "<h3><b>Project Title:</b> Imagedata Augmentation and Image Classification</h3>\n",
        "<h4>Project Notebook</h4>\n",
        "\n",
        "<blockquote style=\"border-left: 4px solid #4285F4; padding-left: 15px;\">\n",
        "  <strong>Created by:</strong> Koustab Ghosh<sup>1</sup> & Sujoy Kumar Biswas<sup>2</sup><br>\n",
        "  <strong>Designation:</strong>\n",
        "  <ol style=\"margin-top: 5px; padding-left: 20px; font-size: 0.9em;\">\n",
        "    <li>Researcher, IDEAS-TIH, Indian Statistical Institute, Kolkata</li>\n",
        "    <li>Head of Research & Innovation, IDEAS-TIH, Indian Statistical Institute, Kolkata</li>\n",
        "  </ol>\n",
        "</blockquote>\n",
        "<hr style=\"width:100%;\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q1-markdown"
      },
      "source": [
        "### Question 1: Import Libraries and Load Image (5 Marks)\n",
        "\n",
        "Import `numpy` as `np` and `cv2`. Download the image 'moon-pexels-frank-cone.jpg' from https://drive.google.com/drive/folders/1TeLp4U4NsXCSgClbF7ODBsaLKpHSWeQr?usp=sharing and load it into a variable named `original_image` using OpenCV. Print the shape of the loaded image.\n",
        "\n",
        "**Hint:** Use `cv2.imread()` to load the image and `.shape` to get its dimensions.\n",
        "\n",
        "**Expected Output:** A tuple representing the shape of the image (height, width, channels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1-code",
        "outputId": "dc2c21f0-6c85-4ce3-c5fb-283e9dc83b23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "original_image = cv2.imread('moon-pexels-frank-cone.jpg')\n",
        "\n",
        "if original_image is not None:\n",
        "    print(original_image.shape)\n",
        "else:\n",
        "    print(\"Error: Image not found. Please check the file path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q2-markdown"
      },
      "source": [
        "### Question 2: Convert to Grayscale (5 Marks)\n",
        "\n",
        "Convert the `original_image` to grayscale using OpenCV's `cvtColor` function. Store the result in a variable named `grayscale_image`. Print the shape of the new grayscale image.\n",
        "\n",
        "**Hint:** Use `cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)`. The shape of the grayscale image will have two dimensions instead of three.\n",
        "\n",
        "**Expected Output:** A tuple representing the shape of the grayscale image (height, width)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2-code",
        "outputId": "c9369641-da7f-4191-ac98-f6bacc5c2ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640)\n"
          ]
        }
      ],
      "source": [
        "grayscale_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "print(grayscale_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 5,
        "id": "q3-markdown"
      },
      "source": [
        "### Question 3: Save the Grayscale Image (5 Marks)\n",
        "\n",
        "Save your `grayscale_image` to a file named `graymoon.jpg`.\n",
        "\n",
        "**Hint:** Use the `cv2.imwrite('filename.jpg', image_variable)` function.\n",
        "\n",
        "**Expected Output:** No direct output, but a file named `graymoon.jpg` will be created in your workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3-code",
        "outputId": "dea7154c-f639-42e1-91d7-bc50e4ea359c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'graymoon.jpg' has been successfully saved to your workspace.\n"
          ]
        }
      ],
      "source": [
        "cv2.imwrite('graymoon.jpg', grayscale_image)\n",
        "\n",
        "print(\"File 'graymoon.jpg' has been successfully saved to your workspace.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q4-markdown"
      },
      "source": [
        "### Question 4: Shift the Image (10 Marks)\n",
        "\n",
        "Create a transformation matrix `M` to shift the `original_image` 50 pixels to the right and 100 pixels down. Apply this transformation using `cv2.warpAffine` and store the result in `shifted_image`. Print the shape of `shifted_image`.\n",
        "\n",
        "**Hint:** The matrix `M` will be a 2x3 NumPy float32 array: `np.float32([[1, 0, 50], [0, 1, 100]])`. The output shape should be the same as the original image.\n",
        "\n",
        "**Expected Output:** The shape of the shifted image, which will be identical to the original image's shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4-code",
        "outputId": "9d4d7a1b-d0e0-4f9d-ded1-0488b6fd450b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 640, 3)\n"
          ]
        }
      ],
      "source": [
        "M = np.float32([[1, 0, 50], [0, 1, 100]])\n",
        "\n",
        "rows, cols = original_image.shape[:2]\n",
        "\n",
        "shifted_image = cv2.warpAffine(original_image, M, (cols, rows))\n",
        "\n",
        "print(shifted_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q5-markdown"
      },
      "source": [
        "### Question 5: Resize the Image (10 Marks)\n",
        "\n",
        "Resize the `original_image` to be 150 pixels wide and 100 pixels tall. Store the result in a variable named `resized_image` and print its new shape.\n",
        "\n",
        "**Hint:** Use the `cv2.resize()` function. The desired size is passed as a tuple `(width, height)`.\n",
        "\n",
        "**Expected Output:** The tuple `(100, 150, 3)` representing the new shape (height, width, channels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5-code",
        "outputId": "0e36662f-21d4-418a-beac-4069d5eb657f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 150, 3)\n"
          ]
        }
      ],
      "source": [
        "new_dimensions = (150, 100)\n",
        "\n",
        "resized_image = cv2.resize(original_image, new_dimensions)\n",
        "\n",
        "print(resized_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q6-markdown"
      },
      "source": [
        "### Question 6: Rotate the Image (10 Marks)\n",
        "\n",
        "Rotate the `original_image` by 90 degrees counter-clockwise around its center. Store the result in a variable named `rotated_image` and print its shape.\n",
        "\n",
        "**Hint:** First, get the image dimensions. Then, create a rotation matrix using `cv2.getRotationMatrix2D(center, angle, scale)`. Finally, apply it with `cv2.warpAffine`.\n",
        "\n",
        "**Expected Output:** The shape of the rotated image. Note that the height and width will be swapped compared to the original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6-code",
        "outputId": "b68ac717-935a-4d08-9bb5-f854e2880e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(640, 800, 3)\n"
          ]
        }
      ],
      "source": [
        "(h, w) = original_image.shape[:2]\n",
        "\n",
        "center = (w // 2, h // 2)\n",
        "\n",
        "M = cv2.getRotationMatrix2D(center, 90, 1.0)\n",
        "\n",
        "rotated_image = cv2.warpAffine(original_image, M, (h, w))\n",
        "\n",
        "print(rotated_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 10,
        "id": "q7-markdown"
      },
      "source": [
        "### Question 7: Download and Unzip Cat/Dog Data (10 Marks)\n",
        "\n",
        "Download the Cat and Dog image dataset from the provided data link and then unzip it. This will create a 'Cat_Dog_data' directory.\n",
        "\n",
        "**Hint:** Download and unzip to extract the files.\n",
        "\n",
        "**Expected Output:** No direct Python output, but the cell's log should show the download and extraction process completing successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7-code",
        "outputId": "06e5be96-cd97-4516-d821-d1f19b4a6b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Success: 'Cat_Dog_data' directory created and extracted!\n",
            "Contents: ['test', 'train', '.DS_Store']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!unzip -q Cat_Dog_data.zip\n",
        "\n",
        "if os.path.exists('Cat_Dog_data'):\n",
        "    print(\"Success: 'Cat_Dog_data' directory created and extracted!\")\n",
        "\n",
        "    print(\"Contents:\", os.listdir('Cat_Dog_data'))\n",
        "else:\n",
        "    print(\"Error: 'Cat_Dog_data.zip' not found in the sidebar. Please upload it first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q8-markdown"
      },
      "source": [
        "### Question 8: Create an Image Transform Pipeline (15 Marks)\n",
        "\n",
        "Import `torch` and necessary modules from `torchvision`. Define a transform pipeline named `train_transform` that resizes images to 255x255, randomly flips them horizontally, and then converts them to a tensor.\n",
        "\n",
        "**Hint:** Use `transforms.Compose()` with a list containing `transforms.Resize()`, `transforms.RandomHorizontalFlip()`, and `transforms.ToTensor()`.\n",
        "\n",
        "**Expected Output:** No output, but the `train_transform` object should be created successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8-code",
        "outputId": "efdb31d1-50af-42ac-bcf0-98e3953f9007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compose(\n",
            "    Resize(size=(255, 255), interpolation=bilinear, max_size=None, antialias=True)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    ToTensor()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((255, 255)),\n",
        "\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "print(train_transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q9-markdown"
      },
      "source": [
        "### Question 9: Create an ImageFolder Dataset (15 Marks)\n",
        "\n",
        "Create an `ImageFolder` dataset named `train_dataset` from the `'Cat_Dog_data/train'` directory, applying the `train_transform` pipeline you just created. Print the total number of images found in the dataset.\n",
        "\n",
        "**Hint:** Use `datasets.ImageFolder(data_dir, transform=your_transform)`. The number of images is the length of the dataset object, which you can get with `len()`.\n",
        "\n",
        "**Expected Output:** A printout of the number of images in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9-code",
        "outputId": "aab5efc8-fe03-4315-f171-f66f8d61234f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images in the training dataset: 22500\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "train_dir = 'Cat_Dog_data/train'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "\n",
        "print(f\"Total number of images in the training dataset: {len(train_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "points": 15,
        "id": "q10-markdown"
      },
      "source": [
        "### Question 10: Create a DataLoader (15 Marks)\n",
        "\n",
        "Create a `DataLoader` named `train_loader` from the `train_dataset`. Set the `batch_size` to 64 and `shuffle` to True. Then, retrieve one batch of images and labels from the loader and print the shape of the images tensor and the labels tensor.\n",
        "\n",
        "**Hint:** Use `torch.utils.data.DataLoader()`. To get one batch, use `images, labels = next(iter(train_loader))`. Print `images.shape` and `labels.shape`.\n",
        "\n",
        "**Expected Output:** Two printed tuples representing the shapes of the image batch and the label batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q10-code",
        "outputId": "e672947f-76b4-43a9-f53e-bebf4f794f70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images batch shape: torch.Size([64, 3, 255, 255])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "\n",
        "print(f\"Images batch shape: {images.shape}\")\n",
        "print(f\"Labels batch shape: {labels.shape}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}